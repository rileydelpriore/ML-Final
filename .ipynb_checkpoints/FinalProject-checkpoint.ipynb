{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f3461d1-0ef0-445d-86bf-584fa90d50b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "df = pd.read_csv('basketball.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b589fabb-4973-4319-bc8c-634c5dca400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create test, val and training sets\n",
    "train = (df[df[\"YEAR\"] == 2019])\n",
    "val = (df[df[\"YEAR\"] == 2021])\n",
    "test = (df[df[\"YEAR\"] == 2022])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65d3e858-4354-4b09-8b84-1127f70a7b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def scale (df: pd.DataFrame) -> pd.DataFrame:\n",
    "    #Calculate scaling parameters based on training data\n",
    "    #Scaling the data so that I can look at regression coefficients on a comparable basis to determine which features the load is sensitive to.\n",
    "    #print(train)\n",
    "    non_label = list(filter(lambda x: x != 'POSTSEASON', df.columns))\n",
    "    subset = df[non_label]\n",
    "\n",
    "    # Mapping feature to it's mean and sd\n",
    "    means = dict(subset.mean())\n",
    "    sds = dict(subset.std())\n",
    "\n",
    "    # Loop through and do the math\n",
    "    for col in means:\n",
    "        df[col] = (df[col] - means[col])/sds[col]\n",
    "\n",
    "    return df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf5bdcad-8b1e-455b-8276-1d80dcf2967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def preprocess (df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ## preprocess and split the data\n",
    "    df = df.dropna(subset = [\"POSTSEASON\", \"SEED\", \"YEAR\"])\n",
    "    \n",
    "    \n",
    "    df[\"POSTSEASON\"] = df[\"POSTSEASON\"].replace({\"Champions\" : 1, \"2ND\" : 2, \"F4\" : 3, \"E8\" : 4, \"S16\" : 5, \"R32\" : 6, \"R64\" : 7})\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == object:\n",
    "                df[column], _ = pd.factorize(df[column])\n",
    "            \n",
    "    df = scale(df)\n",
    "    return df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "828b520b-b14e-44d6-ad18-7dfde87c60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    # Drop rows with missing values in specified columns\n",
    "    df = df.dropna(subset=[\"POSTSEASON\", \"SEED\"])\n",
    "    \n",
    "    # Map values in the \"POSTSEASON\" column\n",
    "    postseason_mapping = {\"Champions\": 1, \"2ND\": 2, \"F4\": 3, \"E8\": 4, \"S16\": 5, \"R32\": 6, \"R64\": 7}\n",
    "    df[\"POSTSEASON\"] = df[\"POSTSEASON\"].replace(postseason_mapping)\n",
    "    \n",
    "    # Convert object type columns to numerical labels, excluding \"POSTSEASON\"\n",
    "    for column in df.select_dtypes(include=[\"object\"]).columns:\n",
    "        if column != \"POSTSEASON\": ##and column != \"TEAM\":  # Exclude \"POSTSEASON\" and \"TEAM\" columns\n",
    "            df[column], _ = pd.factorize(df[column])\n",
    "\n",
    "    # Scale numerical columns excluding \"POSTSEASON\"\n",
    "    nonLabel = list(filter(lambda x: x not in [\"POSTSEASON\"], df.columns))\n",
    "    subset = df[nonLabel]\n",
    "\n",
    "    ##numeric_columns = df.select_dtypes(include=[\"number\"]).columns\n",
    "    ##numeric_columns = numeric_columns.drop([\"POSTSEASON\"])  # Exclude \"POSTSEASON\" column\n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_columns] = scaler.fit_transform(subset)\n",
    "    print(df)\n",
    "    # Ensure no NaN values in the \"YEAR\" column\n",
    "    df = df.dropna(subset=[\"YEAR\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6abecb9-d2e7-4b99-b852-69eecaa01717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def preprocess(df: pd.DataFrame) -> pd.DataFrame:\\n    # Drop rows with missing values in specified columns\\n    df = df.dropna(subset=[\"POSTSEASON\", \"SEED\", \"YEAR\"])\\n    \\n    # Convert \\'POSTSEASON\\' to numerical labels\\n    postseason_mapping = {\"Champions\": 1, \"2ND\": 2, \"F4\": 3, \"E8\": 4, \"S16\": 5, \"R32\": 6, \"R64\": 7}\\n    df[\"POSTSEASON\"] = df[\"POSTSEASON\"].replace(postseason_mapping)\\n    \\n    # Convert object type columns to numerical labels\\n    for column in df.select_dtypes(include=[\"object\"]).columns:\\n        if column != \"POSTSEASON\":  # Exclude \"POSTSEASON\" column\\n            df[column], _ = pd.factorize(df[column])\\n    \\n    # Scale numerical columns excluding \"POSTSEASON\"\\n    numeric_columns = df.select_dtypes(include=[\"number\"]).columns\\n    numeric_columns = numeric_columns.drop(\"POSTSEASON\")  # Exclude \"POSTSEASON\" column\\n    scaler = StandardScaler()\\n    df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\\n    \\n    return df'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def preprocess(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Drop rows with missing values in specified columns\n",
    "    df = df.dropna(subset=[\"POSTSEASON\", \"SEED\", \"YEAR\"])\n",
    "    \n",
    "    # Convert 'POSTSEASON' to numerical labels\n",
    "    postseason_mapping = {\"Champions\": 1, \"2ND\": 2, \"F4\": 3, \"E8\": 4, \"S16\": 5, \"R32\": 6, \"R64\": 7}\n",
    "    df[\"POSTSEASON\"] = df[\"POSTSEASON\"].replace(postseason_mapping)\n",
    "    \n",
    "    # Convert object type columns to numerical labels\n",
    "    for column in df.select_dtypes(include=[\"object\"]).columns:\n",
    "        if column != \"POSTSEASON\":  # Exclude \"POSTSEASON\" column\n",
    "            df[column], _ = pd.factorize(df[column])\n",
    "    \n",
    "    # Scale numerical columns excluding \"POSTSEASON\"\n",
    "    numeric_columns = df.select_dtypes(include=[\"number\"]).columns\n",
    "    numeric_columns = numeric_columns.drop(\"POSTSEASON\")  # Exclude \"POSTSEASON\" column\n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "    \n",
    "    return df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34859ec5-fe56-4b03-bf3a-afbe263f88a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TEAM  CONF   G   W  ADJOE  ADJDE  BARTHAG  EFG_O  EFG_D   TOR  ...  \\\n",
      "708      0     0  38  31  115.2   85.2   0.9696   53.5   43.0  17.7  ...   \n",
      "713      1     1  38  35  123.0   89.9   0.9736   55.2   44.7  14.7  ...   \n",
      "725      2     1  38  32  118.9   89.2   0.9646   53.6   45.0  17.5  ...   \n",
      "726      3     2  36  26  122.8   94.3   0.9539   53.6   49.0  15.8  ...   \n",
      "736      4     3  37  30  117.5   89.8   0.9568   53.0   46.6  18.6  ...   \n",
      "...    ...   ...  ..  ..    ...    ...      ...    ...    ...   ...  ...   \n",
      "3113    63     5  37  33  115.7   90.5   0.9439   52.1   42.5  16.5  ...   \n",
      "3121    64     2  37  30  114.6   85.6   0.9665   51.6   44.1  13.9  ...   \n",
      "3136    65    11  38  25  108.1   91.7   0.8687   52.0   46.4  17.8  ...   \n",
      "3140    66     3  35  28  117.9   96.6   0.9081   51.2   49.9  17.9  ...   \n",
      "3141    67     3  36  31  122.8   95.2   0.9488   55.3   48.1  15.8  ...   \n",
      "\n",
      "       FTR  FTRD  2P_O  2P_D  3P_O  3P_D  ADJ_T   WAB  SEED  YEAR  \n",
      "708   32.9  36.6  52.8  41.9  36.5  29.7   67.5   7.0   3.0  2019  \n",
      "713   29.1  26.3  52.5  45.7  39.5  28.9   60.7  11.1   1.0  2019  \n",
      "725   33.2  24.0  58.0  45.0  30.8  29.9   73.6  11.2   1.0  2019  \n",
      "726   29.9  31.7  51.5  47.2  37.4  34.2   67.0   6.1   3.0  2019  \n",
      "736   41.9  26.8  52.9  43.6  35.4  34.3   66.9   8.8   2.0  2019  \n",
      "...    ...   ...   ...   ...   ...   ...    ...   ...   ...   ...  \n",
      "3113  31.6  37.3  51.3  43.0  35.5  27.9   67.3   7.8   3.0  2019  \n",
      "3121  27.5  24.1  51.8  44.3  34.2  29.1   65.9   9.2   2.0  2019  \n",
      "3136  29.4  33.9  51.6  48.8  35.1  29.0   65.4  -1.1  12.0  2019  \n",
      "3140  37.1  33.1  52.9  49.4  31.9  33.7   71.2   7.3   3.0  2019  \n",
      "3141  33.3  34.9  55.4  44.7  36.7  35.4   68.8   9.9   2.0  2019  \n",
      "\n",
      "[68 rows x 23 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_f/985z51xd7t7d6n72bm4tzz700000gn/T/ipykernel_82182/3210022048.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"POSTSEASON\"] = df[\"POSTSEASON\"].replace(postseason_mapping)\n",
      "/var/folders/_f/985z51xd7t7d6n72bm4tzz700000gn/T/ipykernel_82182/3210022048.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column], _ = pd.factorize(df[column])\n",
      "/var/folders/_f/985z51xd7t7d6n72bm4tzz700000gn/T/ipykernel_82182/3210022048.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column], _ = pd.factorize(df[column])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'numeric_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m test \u001b[38;5;241m=\u001b[39m preprocess(test)\n\u001b[1;32m      3\u001b[0m val \u001b[38;5;241m=\u001b[39m preprocess(val)\n",
      "Cell \u001b[0;32mIn[41], line 21\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m##numeric_columns = df.select_dtypes(include=[\"number\"]).columns\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m##numeric_columns = numeric_columns.drop([\"POSTSEASON\"])  # Exclude \"POSTSEASON\" column\u001b[39;00m\n\u001b[1;32m     20\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m---> 21\u001b[0m df[\u001b[43mnumeric_columns\u001b[49m] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(subset)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Ensure no NaN values in the \"YEAR\" column\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numeric_columns' is not defined"
     ]
    }
   ],
   "source": [
    "train = preprocess(train)\n",
    "test = preprocess(test)\n",
    "val = preprocess(val)\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "173da65b-ef2b-4157-96cf-3995109cfa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run logistic regression\n",
    "def fit_predict(train_fname: pd.DataFrame, test_fname: pd.DataFrame) -> np.array:\n",
    "    classifier = LogisticRegression(max_iter=1000)\n",
    "    # Get predictions\n",
    "    #print(train)\n",
    "    \n",
    "    X_train = train.drop(\"POSTSEASON\", axis=1)\n",
    "    Y_train = train[\"POSTSEASON\"]\n",
    "    X_test = test.drop(\"POSTSEASON\", axis=1)\n",
    "    \n",
    "    classifier.fit(X_train, Y_train)\n",
    "    Y_pred = classifier.predict(X_test)\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b51ab02-4347-4f9e-a4d3-23c92757198f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Texas Tech'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_f/985z51xd7t7d6n72bm4tzz700000gn/T/ipykernel_82182/2472863978.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/_f/985z51xd7t7d6n72bm4tzz700000gn/T/ipykernel_82182/198203261.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(train_fname, test_fname)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POSTSEASON\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"POSTSEASON\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POSTSEASON\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1149\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1204\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m   1209\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    618\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         raise ValueError(\n\u001b[1;32m   1143\u001b[0m             \u001b[0;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         )\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1147\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    912\u001b[0m                         )\n\u001b[1;32m    913\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m                 raise ValueError(\n\u001b[1;32m    918\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2082\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2084\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2085\u001b[0m         if (\n\u001b[1;32m   2086\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2087\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Texas Tech'"
     ]
    }
   ],
   "source": [
    "def score(test: pd.DataFrame, Y_pred: np.array) -> list[float]:\n",
    "    test = preprocess(test)\n",
    "    Y = test[test.columns[test.columns.isin(['POSTSEASON'])]]\n",
    "\n",
    "    precision = metrics.precision_score(Y, Y_pred)\n",
    "    recall = metrics.recall_score(Y, Y_pred)\n",
    "    f1 = metrics.f1_score(Y, Y_pred)\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "Y_pred = fit_predict(train, val)\n",
    "print(score(val, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868fed74-9497-497a-8f88-1a48f79517a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
